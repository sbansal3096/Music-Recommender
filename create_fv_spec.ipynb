{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, image_size, image_size)\n",
    "else:\n",
    "    input_shape = (image_size, image_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.6/site-packages/keras/models.py:251: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "feature_vec_model = load_model('music_feature_extractor.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spect_files = glob.glob('prediction/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file in spect_files:\n",
    "    img = load_img('{}'.format(file), target_size=(256, 256))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255\n",
    "    \n",
    "    feature_vec = feature_vec_model.predict(img_array)\n",
    "    \n",
    "    s = file\n",
    "    s = s.replace('.png','')\n",
    "    s = s.split('/')[1]\n",
    "    file_info = s\n",
    "    \n",
    "    out_file_name = '{}.npy'.format(file_info)\n",
    "    out_file_dir = 'featurevec'\n",
    "    out_file_path = '{}/{}'.format(out_file_dir, out_file_name)\n",
    "    \n",
    "    np.save(out_file_path, feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npy_files = glob.glob('{}/*'.format(out_file_dir))\n",
    "npy_files[0:5]\n",
    "test_file = npy_files[0]\n",
    "f = np.load(test_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23602411,  0.18019833,  0.03054499,  0.1181217 ,  0.09782959,\n",
       "         0.00420815,  0.03534144,  0.03907922, -0.05087778, -0.05565744,\n",
       "         0.00942106,  0.05003373, -0.12117283,  0.06812377, -0.05841454,\n",
       "        -0.07658634,  0.11915127,  0.23287998,  0.25620511, -0.01174169,\n",
       "        -0.04471665,  0.0249941 ,  0.23224388,  0.16434112,  0.06344037,\n",
       "         0.00173827, -0.04466339,  0.24462131,  0.29728419, -0.00071559,\n",
       "        -0.13982852,  0.0367009 ,  0.22480614, -0.06886587,  0.061297  ,\n",
       "        -0.09280959, -0.01094733, -0.04689184,  0.1188684 , -0.00386638,\n",
       "         0.17636554, -0.01600155, -0.17194647,  0.01591108, -0.12676246,\n",
       "         0.09624284, -0.04650603,  0.13999116,  0.137064  ,  0.18384598,\n",
       "         0.00711843,  0.32394654,  0.18080649,  0.11525117, -0.17188308,\n",
       "        -0.11316436,  0.07226742,  0.25723916, -0.09114978,  0.07095664,\n",
       "         0.311611  ,  0.1387375 , -0.19493261, -0.06197329, -0.01950612,\n",
       "         0.0149703 ,  0.08811898, -0.01239409,  0.19403614,  0.18316038,\n",
       "         0.04924453, -0.01256423, -0.15494585, -0.13850802,  0.10922539,\n",
       "         0.43931475,  0.23298028,  0.0105681 ,  0.21703109, -0.02385034,\n",
       "         0.08631285,  0.27207154, -0.03450649,  0.1525483 ,  0.11448825,\n",
       "        -0.15099345,  0.14337528,  0.05880312,  0.11952098,  0.01120206,\n",
       "        -0.06183368, -0.13099216,  0.01193452,  0.02062371, -0.24932167,\n",
       "        -0.10449286,  0.12950063,  0.04133217,  0.11668888,  0.07250808,\n",
       "         0.27739266,  0.10109972, -0.06295502,  0.05658369,  0.15977491,\n",
       "         0.28301367, -0.09442387,  0.03826632,  0.0493063 ,  0.09860105,\n",
       "         0.12656979, -0.04601463, -0.07736729, -0.10329451, -0.02569786,\n",
       "         0.34924713,  0.04873637,  0.10335287, -0.02872657,  0.0339871 ,\n",
       "         0.00381687, -0.15215826,  0.08469434, -0.09066057, -0.01404728,\n",
       "        -0.18330932, -0.1223262 , -0.14141062]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
